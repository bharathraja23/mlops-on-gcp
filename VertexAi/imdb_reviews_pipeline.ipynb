{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "abe9a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id=\"dna-verizonpoc\"\n",
    "region=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e51f4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from joblib import load\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "603d5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component( base_image=\"gcr.io/dna-verizonpoc/movie_reviews_base_image:latest\")\n",
    "def get_data(\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    "    \n",
    "):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    import pandas as pd\n",
    "    # import some data to play with\n",
    "    \n",
    "    \n",
    "    data_raw = pd.read_csv(\"gs://verexai_automl_text_data/pipeline_root/custommodel/imdb_reviews/data/imdb_movie_reviews_data.csv\")\n",
    "    train, test = tts(data_raw, test_size=0.3)\n",
    "    \n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1af0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"gcr.io/dna-verizonpoc/movie_reviews_base_image:latest\")\n",
    "def train_movie_reviews_model(\n",
    "    dataset: Input[Dataset],\n",
    "    model_artifact: Output[Model]\n",
    "):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from os import system\n",
    "    import subprocess\n",
    "    import sys\n",
    "    from joblib import dump, load # used for saving and loading sklearn objects\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    imdb_train = pd.read_csv(dataset.path)\n",
    "    gcs_model_path = \"gs://verexai_automl_text_data/pipeline_root/custommodel/imdb_reviews/model/model.joblib\"\n",
    "    \n",
    "    if not os.path.exists('model'):\n",
    "        system(\"mkdir 'model'\")\n",
    "    \n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    text_clf.fit(imdb_train.text, imdb_train.label)\n",
    "    score=text_clf.score(imdb_train.text, imdb_train.label)\n",
    "    dump(text_clf,'model/model.joblib')\n",
    "    dump('model/model.joblib',model_artifact.path)\n",
    "    subprocess.check_call(['gsutil', 'cp', 'model/model.joblib',gcs_model_path],stderr=sys.stdout)\n",
    "    model_artifact.metadata[\"model\"] = gcs_model_path\n",
    "    model_artifact.metadata[\"train_score\"] = float(score)\n",
    "    model_artifact.metadata[\"framework\"] = \"Scikit-learn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bed6332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"gcr.io/dna-verizonpoc/movie_reviews_base_image:latest\")\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    movie_review_model: Input[Model],\n",
    "    threshold : float,\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    smetrics: Output[Metrics]\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):\n",
    "    import pandas as pd\n",
    "    from joblib import dump, load\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import os\n",
    "    from os import system\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    if not os.path.exists('model'):\n",
    "        system(\"mkdir 'model'\")  \n",
    "        \n",
    "    imdb_test = pd.read_csv(test_set.path)\n",
    "    print(movie_review_model.metadata[\"model\"])\n",
    "    subprocess.check_call(['gsutil', 'cp', movie_review_model.metadata[\"model\"], 'model/model.joblib'],stderr=sys.stdout)\n",
    "    \n",
    "    model = load('model/model.joblib')\n",
    "    print(type(model))\n",
    "    score = model.score(imdb_test.text, imdb_test.label.astype(str))\n",
    "    print(\"score = {} \".format(score))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_pred = model.predict(imdb_test['text'].values)\n",
    "    \n",
    "    metrics.log_confusion_matrix(\n",
    "       [\"False\", \"True\"],\n",
    "       confusion_matrix(\n",
    "           imdb_test['label'].values.astype(str), y_pred.astype(str)\n",
    "       ).tolist(),  # .tolist() to convert np array to list.\n",
    "    )\n",
    "    \n",
    "    #movie_review_model.metadata[\"test_score\"] = float(score)\n",
    "    smetrics.log_metric(\"score\", float(score))\n",
    "    \n",
    "    if float(score) > threshold:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    return (dep_decision,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "546b034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=\"gs://verexai_automl_text_data/pipeline_root/custommodel/imdb_reviews/\",\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"custom-pipeline-text-sentiment-anlaysis\",\n",
    ")\n",
    "def pipeline(\n",
    "serving_container_image_uri: str = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\",\n",
    "):\n",
    "    dataset_op = get_data()\n",
    "    train_op = train_movie_reviews_model(dataset_op.outputs[\"dataset_train\"])\n",
    "    eval_op = eval_model(\n",
    "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
    "        movie_review_model=train_op.outputs[\"model_artifact\"],\n",
    "        threshold=0.85,\n",
    "    )\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project_id,\n",
    "        display_name=\"pipelines-created-endpoint-textsa\",\n",
    "    )\n",
    "    \n",
    "    model_upload_op = gcc_aip.ModelUploadOp(\n",
    "        project=project_id,\n",
    "        display_name=\"movie_reviews_model\",\n",
    "        artifact_uri=\"gs://verexai_automl_text_data/pipeline_root/custommodel/imdb_reviews/model\",\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "    )\n",
    "    model_upload_op.after(eval_op)\n",
    "    \n",
    "#    deploy_decision_op = derive_deploy_decision(\"0.85\", eval_op.outputs[\"smetrics\"])\n",
    "    \n",
    "    with dsl.Condition(\n",
    "        eval_op.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):    \n",
    "        model_deploy_op = gcc_aip.ModelDeployOp(         \n",
    "            project=project_id,\n",
    "            endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "            model=model_upload_op.outputs[\"model\"],\n",
    "            deployed_model_display_name=\"movie_reviews_model\",\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )\n",
    "    \n",
    "    \n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='movie_review_pipeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de5a3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/custom-pipeline-text-sentiment-anlaysis-20210827110437?project=dna-verizonpoc\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "                project_id=\"dna-verizonpoc\",\n",
    "                region=\"us-central1\"\n",
    "                )\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "    'movie_review_pipeline.json',\n",
    "    enable_caching=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6df120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
